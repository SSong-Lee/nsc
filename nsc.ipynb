{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import winsound as ws\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2023_02_05_23_56_22.h5')\n",
    "model.summary()\n",
    "\n",
    "open_start_time = 0\n",
    "close_start_time = 0\n",
    "\n",
    "COUNT = 0\n",
    "def beepsound():\n",
    "    freq = 2000    # range : 37 ~ 32767\n",
    "    dur = 1000     # ms\n",
    "    ws.Beep(freq, dur) # winsound.Beep(frequency, duration)\n",
    "\n",
    "# print(beepsound())\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "# cap = cv2.VideoCapture('videos/2.mp4')\n",
    "lst_l = [] \n",
    "lst_r = []\n",
    "lst_b = []\n",
    "lst_log = []\n",
    "\n",
    "video_file = '../CV2/video/sarang1.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    state_both = (pred_l + pred_r) / 2\n",
    "    \n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    " \n",
    "    cv2.imshow('result', img)\n",
    "    \n",
    "    #while True:\n",
    "    close_start_time = time.time()\n",
    "    time.sleep(0.4)\n",
    "    if float(state_both) >= 0.2 :\n",
    "        print('normal')\n",
    "    else: # float(state_both) < 0.2 :\n",
    "#        print('blink')    \n",
    "        print(close_start_time)\n",
    "        t = time.time() - close_start_time\n",
    "        \n",
    "        print(t)\n",
    "        if t >= 0.4:\n",
    "   #         print(\"ALARM: state_both has been less than 0.3 for 3 seconds or more.\")\n",
    "            print(beepsound())\n",
    "            open_start_time =time.time()\n",
    "            print(open_start_time)\n",
    "            now = datetime.datetime.now()\n",
    "            #print now \n",
    "            print(now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            lst_log.append(now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            lst_l.append(state_l)\n",
    "            lst_r.append(state_r)\n",
    "            lst_b.append(float(state_both))\n",
    "            print('sleep')\n",
    "            COUNT += 1\n",
    "            print(COUNT)\n",
    "#                     break\n",
    "        else:\n",
    "            print('NO')\n",
    "    \n",
    "    \n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    print(COUNT)\n",
    "    print(lst_log)\n",
    "    print(lst_l)\n",
    "    print(lst_r)\n",
    "    print(lst_b)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
